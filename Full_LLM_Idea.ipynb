{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install groq openai multion boto3 mem0ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTqKx_bxyIKE",
        "outputId": "cfa8a623-d420-4289-b092-2e4b71770f8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.36.1)\n",
            "Requirement already satisfied: multion in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.34.145)\n",
            "Requirement already satisfied: mem0ai in /usr/local/lib/python3.10/dist-packages (0.0.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: agentops<0.3.0,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from multion) (0.2.6)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from multion) (0.4.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.145 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.34.145)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.2)\n",
            "Requirement already satisfied: posthog<4.0.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mem0ai) (3.5.0)\n",
            "Requirement already satisfied: qdrant-client<2.0.0,>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from mem0ai) (1.10.1)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from agentops<0.3.0,>=0.2.3->multion) (2.31.0)\n",
            "Requirement already satisfied: psutil==5.9.8 in /usr/local/lib/python3.10/dist-packages (from agentops<0.3.0,>=0.2.3->multion) (5.9.8)\n",
            "Requirement already satisfied: packaging==23.2 in /usr/local/lib/python3.10/dist-packages (from agentops<0.3.0,>=0.2.3->multion) (23.2)\n",
            "Requirement already satisfied: termcolor==2.4.0 in /usr/local/lib/python3.10/dist-packages (from agentops<0.3.0,>=0.2.3->multion) (2.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->agentops<0.3.0,>=0.2.3->multion) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->agentops<0.3.0,>=0.2.3->multion) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->agentops<0.3.0,>=0.2.3->multion) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->agentops<0.3.0,>=0.2.3->multion) (2024.7.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.145->boto3) (2.8.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (1.65.1)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (1.65.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (1.25.2)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (2.10.1)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.9.1->mem0ai) (5.27.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.9.1->mem0ai) (67.7.2)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (4.1.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx<1,>=0.23.0->groq) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx<1,>=0.23.0->groq) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIeV1mtA49b3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "srcdyLn0s8UF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from mem0 import Memory\n",
        "from multion.client import MultiOn\n",
        "import json\n",
        "import logging\n",
        "import base64\n",
        "import boto3\n",
        "import openai\n",
        "import agentops\n",
        "import time\n",
        "import copy\n",
        "from groq import Groq\n",
        "\n",
        "from mem0 import Memory\n",
        "from botocore.exceptions import ClientError\n",
        "import os\n",
        "import requests\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = Memory()"
      ],
      "metadata": {
        "id": "E7Rn7s2Q_cOI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dn2Z598bs_lb"
      },
      "outputs": [],
      "source": [
        "groq_client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
        ")\n",
        "client = OpenAI()\n",
        "client_multion = MultiOn(api_key=os.environ.get(\"MULTION_API_KEY\"), agentops_api_key=os.environ.get(\"AGENTOPS_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ELrV8h2I_c4l"
      },
      "outputs": [],
      "source": [
        "temperature = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lxJlKYdMujic"
      },
      "outputs": [],
      "source": [
        "# user_prompt = \"\"\"\n",
        "# Shopping for a dress.\n",
        "# \"\"\"\n",
        "\n",
        "user_prompt = \"\"\"\n",
        "Play Lose Yourself by Eminem on Spotify.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "44TqDieOtd9y"
      },
      "outputs": [],
      "source": [
        "system_prompt_llm1_init = \"\"\"\n",
        "You are an assistant that will take a web navigation task as an input and output\n",
        "a detailed chain of thought set of instructions to complete this task. If you\n",
        "require more information than what is given in the original prompt, your output\n",
        "should include asking this question as one of the steps. The question should be\n",
        "formatted using \"quotation marks\" so that it is easier to follow. After you give a response, you will be given\n",
        "feedback by another teacher assistant to iteratively improve your response.\n",
        "Essentially, you are the actor in an actor-critic model. The goal is to\n",
        "create a set of instructions for another LLM agent to perform using web navigation,\n",
        "so the response should be framed for an LLM, not a human. For context, the LLM has\n",
        "access to Google Chrome and maybe other applications on the user's laptop.\n",
        "\n",
        "Types of questions to ask the user are about:\n",
        "1) clarify specificity of the inputted prompt\n",
        "2) clarify the intent of the inputted prompt\n",
        "3) credentials to log into websites (usernames and passwords)\n",
        "(Please assume the user has an account they ask about unless specified otherwise.\n",
        "Ask them for the credentials, not whether they have the account.)\n",
        "\n",
        "This clarification may be needed because the user of this product is not an expert\n",
        "at prompting or specificity. For example, if the user wants to watch sports clips,\n",
        "you can ask which sport. Then, if they say soccer, ask if they want recent highlights or\n",
        "soccer clips from any specific time period. Clarifying user intent is crucial.\n",
        "\n",
        "RESPONSE SHOULD BE IN LIST FORMAT, WHERE EACH ELEMENT HAS A SHORT RELEVANT TITLE AND CORRESPONDING DESCRIPTION:\n",
        "[\n",
        "<<<ORIGINAL-PROMPT-FROM-USER>>>: ORIGINAL PROMPT FROM USER ,\n",
        "<<<TITLE-DESCRIPTION>>>: DESCRIPTION OF STEP ,\n",
        "<<<ASK-QUESTION>>>: \"QUESTION TO ASK TO THE USER OF THIS PRODUCT?\" ,\n",
        "``MORE LINES HERE``\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "system_prompt_llm2_init = \"\"\"\n",
        "You are an assistant that will take the proposed chain of thought for completing\n",
        "a web navigation task and output constructive criticism feedback for the chain\n",
        "of thought. Your job is to find flaws in the chain of thought logic, misordered\n",
        "steps, or unnecessary steps. Essentially, you are the critic in an actor-critic model.\n",
        "\n",
        "Some of the questions that the actor asks the user are crucial, like the following:\n",
        "1) clarify specificity of the inputted prompt\n",
        "2) clarify the intent of the inputted prompt\n",
        "3) credentials to log into websites (usernames and passwords)\n",
        "(Please assume the user has an account they ask about unless specified otherwise.\n",
        "Ask them for the credentials, not whether they have the account.)\n",
        "\n",
        "That being said, steps should not be redundant or unnecessary.\n",
        "\n",
        "INPUT FORMAT:\n",
        "[\"{'role': 'user', 'content': 'Initial user prompt here.'}\",\n",
        " '{\\'role\\': \\'assistant\\', \\'content\\': \\'[\n",
        "  \\\\n<<<TITLE-OF-STEP>>>: Step description ,\n",
        "  \\\\n<<<ASK-QUESTION>>>: \"Question to user here (should be as specific as possible)?\"\n",
        "  `MORE-LINES-HERE`'}',']\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "Here is some feedback for the chain of thought so far:\n",
        "<<<TITLE-OF-FEEDBACK>>>: DESCRIPTION OF FEEDBACK ,\n",
        "<<<TITLE-OF-FEEDBACK>>>: DESCRIPTION OF FEEDBACK ,\n",
        "<<<TITLE-OF-FEEDBACK>>>: DESCRIPTION OF FEEDBACK ,\n",
        "`MORE-LINES-HERE`\n",
        "\"\"\"\n",
        "\n",
        "system_prompt_llm1 = \"\"\"\n",
        "You are an assistant that will take a web navigation task as an input and output\n",
        "a detailed chain of thought set of instructions to complete this task.\n",
        "\n",
        "Complete set of inputs:\n",
        "1) Initial user prompt\n",
        "2) Chain of thought produced to complete initial prompt\n",
        "3) Log messages from an LLM agent trying to complete the web navigation task\n",
        "based on the given prompt and chain of thought.\n",
        "\n",
        "Your task is to determine whether the task has been completed or not. If the\n",
        "task has not been completed, create a chain of thought to complete the task\n",
        "from the current state. If the task is completed, output: \"DONE-WITH-TASK\"\n",
        "\n",
        "If the task is not completed:\n",
        "If you require more information than what is given in the original prompt, your output\n",
        "should include asking this question as one of the steps. The question should be\n",
        "formatted using \"quotation marks\" so that it is easier to follow. After you give a response, you will be given\n",
        "feedback by another teacher assistant to iteratively improve your response.\n",
        "Essentially, you are the actor in an actor-critic model. The goal is to\n",
        "create a set of instructions for another LLM agent to perform using web navigation,\n",
        "so the response should be framed for an LLM, not a human. For context, the LLM has\n",
        "access to Google Chrome and maybe other applications on the user's laptop.\n",
        "\n",
        "Types of questions to ask the user are about:\n",
        "1) clarify specificity of the inputted prompt\n",
        "2) clarify the intent of the inputted prompt\n",
        "3) credentials to log into websites (usernames and passwords)\n",
        "(Please assume the user has an account they ask about unless specified otherwise.\n",
        "Ask them for the credentials, not whether they have the account.)\n",
        "\n",
        "This clarification may be needed because the user of this product is not an expert\n",
        "at prompting or specificity. For example, if the user wants to watch sports clips,\n",
        "you can ask which sport. Then, if they say soccer, ask if they want recent highlights or\n",
        "soccer clips from any specific time period. Clarifying user intent is crucial.\n",
        "\n",
        "RESPONSE SHOULD BE IN LIST FORMAT, WHERE EACH ELEMENT HAS A SHORT RELEVANT TITLE AND CORRESPONDING DESCRIPTION:\n",
        "[\n",
        "<<<ORIGINAL-PROMPT-FROM-USER>>>: ORIGINAL PROMPT FROM USER ,\n",
        "<<<TITLE-DESCRIPTION>>>: DESCRIPTION OF STEP ,\n",
        "<<<ASK-QUESTION>>>: \"QUESTION TO ASK TO THE USER OF THIS PRODUCT?\" ,\n",
        "``MORE LINES HERE``\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "system_prompt_llm2 = \"\"\"\n",
        "You are an assistant that will take the proposed chain of thought for completing\n",
        "a web navigation task and output constructive criticism feedback for the chain\n",
        "of thought.\n",
        "\n",
        "Complete set of inputs:\n",
        "1) Initial user prompt\n",
        "2) Chain of thought produced to complete initial prompt\n",
        "3) Log messages from an LLM agent trying to complete the web navigation task\n",
        "based on the given prompt and chain of thought.\n",
        "4) A proposed chain of thought to complete the task in the current state.\n",
        "\n",
        "Your job is to find flaws in the proposed chain of thought logic, misordered\n",
        "steps, or unnecessary steps. Essentially, you are the critic in an actor-critic model.\n",
        "\n",
        "Some of the questions that the actor asks the user are crucial, like the following:\n",
        "1) clarify specificity of the inputted prompt\n",
        "2) clarify the intent of the inputted prompt\n",
        "3) credentials to log into websites (usernames and passwords)\n",
        "(Please assume the user has an account they ask about unless specified otherwise.\n",
        "Ask them for the credentials, not whether they have the account.)\n",
        "\n",
        "That being said, steps should not be redundant or unnecessary.\n",
        "\n",
        "INPUT FORMAT FOR PROPOSED CHAIN OF THOUGHT:\n",
        "[\"{'role': 'user', 'content': 'Initial user prompt here.'}\",\n",
        " '{\\'role\\': \\'assistant\\', \\'content\\': \\'[\n",
        "  \\\\n<<<TITLE-OF-STEP>>>: Step description ,\n",
        "  \\\\n<<<ASK-QUESTION>>>: \"Question to user here (should be as specific as possible)?\"\n",
        "  `MORE-LINES-HERE`'}',']\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "Here is some feedback for the chain of thought so far:\n",
        "<<<TITLE-OF-FEEDBACK>>>: DESCRIPTION OF FEEDBACK ,\n",
        "<<<TITLE-OF-FEEDBACK>>>: DESCRIPTION OF FEEDBACK ,\n",
        "<<<TITLE-OF-FEEDBACK>>>: DESCRIPTION OF FEEDBACK ,\n",
        "`MORE-LINES-HERE`\n",
        "\"\"\"\n",
        "\n",
        "bedrock = boto3.client(\n",
        "    service_name=\"bedrock-runtime\",\n",
        "    region_name=\"us-east-1\"\n",
        ")\n",
        "info = boto3.client(\n",
        "    service_name=\"bedrock\",\n",
        "    region_name=\"us-east-1\"\n",
        ")\n",
        "llm_3_prompt = \"\"\"\n",
        "  You are an agent that is working with a tool called MultiOn to perform google search queries for the user.\n",
        "  However, MultiOn often makes mistakes and can get sidetracked and navigate to a page that was not what the user intended.\n",
        "  Additionally, MultiOn can get stuck in a loop where it doesn't know what to do. Given a screenshot of the current page, the\n",
        "  user prompt which has been processed by two LLMs in a Chain-of-Thought style conversation, and descriptions of the action MultiOn is currently\n",
        "  taking, you should output either CONTINUE if you think MultiOn is on the right track, STOP_LLM + the reason why MultiOn is not on the right track if you think MultiOn\n",
        "  is not following the initial user's intent and that MultiOn can be helped with a few clarifications, STOP_HUMAN if MultiOn is unable to use some aspect of the UI such as buttons\n",
        "  and needs the user's help or if the user's intent is unclear or vague, and END if MultiOn has completed the task that the user asked for.\n",
        "\n",
        "  Once again, response should be in a specific format:\n",
        "\n",
        "  1) <<<CONTINUE>>>: <<<N/A>>> (reasoning: multion is on the right track)\n",
        "\n",
        "  2) <<<STOP_LLM>>>: <<<REASON>>> (reasoning: multion is veering from the user's intentions and moving in the wrong direction)\n",
        "\n",
        "  3) <<<STOP_HUMAN>>>: <<<REASON>>> (reasoning: multion is stuck or the user's prompt is too vague and more info is needed)\n",
        "\n",
        "  4) <<<END>>>: <<<N/A>>> (reasoning: the task that the user specified has been completed)\n",
        "  Generate no other text, and format it exactly in one of the ways shown.\n",
        "\"\"\"\n",
        "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_loop(user_prompt, initial_url, system_prompt, max_steps=None):\n",
        "  step = 0\n",
        "  messages = []\n",
        "  create_response = client_multion.sessions.create(\n",
        "    url=initial_url\n",
        "  )\n",
        "  session_id = create_response.session_id\n",
        "  status = \"CONTINUE\"\n",
        "  while status == \"CONTINUE\":\n",
        "      step_response = client_multion.sessions.step(\n",
        "          session_id=session_id,\n",
        "          cmd=user_prompt,\n",
        "          include_screenshot=True\n",
        "      )\n",
        "      status = step_response.status\n",
        "\n",
        "      file_name = \"test{num}.png\"\n",
        "      time.sleep(3)\n",
        "      ss = requests.get(step_response.screenshot)\n",
        "      with open(file_name.format(num=step),'wb') as f:\n",
        "        f.write(ss.content)\n",
        "      response = call_claude(messages, step_response.message, file_name.format(num=step))\n",
        "      step += 1\n",
        "\n",
        "      if(step >= max_steps):\n",
        "        break\n",
        "  return messages, session_id"
      ],
      "metadata": {
        "id": "6g4O-MSX7UNL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "def run_multi_modal_prompt(bedrock_runtime, model_id, messages, max_tokens):\n",
        "    \"\"\"\n",
        "    Invokes a model with a multimodal prompt.\n",
        "    Args:\n",
        "        bedrock_runtime: The Amazon Bedrock boto3 client.\n",
        "        model_id (str): The model ID to use.\n",
        "        messages (JSON) : The messages to send to the model.\n",
        "        max_tokens (int) : The maximum  number of tokens to generate.\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    body = json.dumps(\n",
        "        {\n",
        "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "            \"system\": llm_3_prompt,\n",
        "            \"max_tokens\": max_tokens,\n",
        "             \"messages\": messages\n",
        "        }\n",
        "    )\n",
        "\n",
        "    response = bedrock_runtime.invoke_model(\n",
        "        body=body, modelId=model_id)\n",
        "    response_body = json.loads(response.get('body').read())\n",
        "\n",
        "    return response_body\n",
        "\n",
        "def call_claude(old_messages, input_text, input_image):\n",
        "    try:\n",
        "        bedrock_runtime = boto3.client(service_name='bedrock-runtime')\n",
        "        model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
        "        max_tokens = 1000\n",
        "\n",
        "        # Read reference image from file and encode as base64 strings.\n",
        "        with open(input_image, \"rb\") as image_file:\n",
        "            content_image = base64.b64encode(image_file.read()).decode('utf8')\n",
        "\n",
        "        message = {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "              {\"type\": \"image\", \"source\": {\"type\": \"base64\",\n",
        "                  \"media_type\": \"image/jpeg\", \"data\": content_image}},\n",
        "              {\"type\": \"text\", \"text\": input_text}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        if(old_messages[-1][\"role\"] == \"user\"):\n",
        "          message[\"content\"][1][\"text\"] += old_messages[-1][\"content\"]\n",
        "          old_messages.pop()\n",
        "        old_messages.append(message)\n",
        "        response = run_multi_modal_prompt(\n",
        "            bedrock_runtime, model_id, old_messages, max_tokens)\n",
        "\n",
        "        old_messages[-1][\"content\"] = old_messages[-1][\"content\"][-1][\"text\"]\n",
        "        old_messages.append({\"role\": \"assistant\", \"content\" : response[\"content\"][0][\"text\"]})\n",
        "        return response[\"content\"][0][\"text\"]\n",
        "\n",
        "    except ClientError as err:\n",
        "        message = err.response[\"Error\"][\"Message\"]\n",
        "        logger.error(\"A client error occurred: %s\", message)\n",
        "        print(\"A client error occured: \" +\n",
        "              format(message))"
      ],
      "metadata": {
        "id": "-PnD960x7W4P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TTW3AXfitAH7"
      },
      "outputs": [],
      "source": [
        "# LLM 1 (Initial Proposal)\n",
        "\n",
        "def generate_COT(messages, first=True, max_iters=3):\n",
        "  copy_messages = copy.deepcopy(messages)\n",
        "\n",
        "  completion = groq_client.chat.completions.create(\n",
        "    messages=[{\"role\": \"system\", \"content\": system_prompt_llm1_init if first else system_prompt_llm1}] + copy_messages,\n",
        "    model=\"llama3-8b-8192\",\n",
        "    temperature=temperature,\n",
        "  )\n",
        "\n",
        "  response = completion.choices[0].message.content\n",
        "  copy_messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "  print(\"PROPOSED CHAIN OF THOUGHT:\")\n",
        "  print(response)\n",
        "  print(\"\\n\\n\")\n",
        "\n",
        "  for i in range(max_iters):\n",
        "    # LLM 2\n",
        "    completion = groq_client.chat.completions.create(\n",
        "      model=\"llama3-8b-8192\",\n",
        "      messages=[{\"role\": \"system\", \"content\": system_prompt_llm2_init if first else system_prompt_llm2}, {\"role\": \"user\", \"content\": \"\\n\".join(list(map(str, [copy_messages[0], copy_messages[-1]])))}],\n",
        "      temperature=temperature,\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content\n",
        "    copy_messages.append({\"role\": \"user\", \"content\": response})\n",
        "    # print(\"FEEDBACK\")\n",
        "    # print(response)\n",
        "    # print(\"\\n\\n\")\n",
        "\n",
        "    # LLM 1\n",
        "    completion = groq_client.chat.completions.create(\n",
        "      model=\"llama3-8b-8192\",\n",
        "      messages=[{\"role\": \"system\", \"content\": system_prompt_llm1_init}] + copy_messages,\n",
        "      temperature=temperature,\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content\n",
        "    copy_messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "    # print(\"PROPOSED CHAIN OF THOUGHT:\")\n",
        "    # print(response)\n",
        "    # print(\"\\n\\n\")\n",
        "\n",
        "  final_prompt = copy_messages[-1][\"content\"]\n",
        "  return final_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d5QT4ZhRtUHo"
      },
      "outputs": [],
      "source": [
        "def create_full_loop(user_prompt, initial_url=\"https://google.com/\", max_steps=None):\n",
        "  step = 0\n",
        "  create_response = client_multion.sessions.create(\n",
        "    url=initial_url\n",
        "  )\n",
        "  messages = [{\"role\":\"user\", \"content\": user_prompt}]\n",
        "  multion_prompt = generate_COT(messages)\n",
        "  messages[0][\"content\"] = multion_prompt\n",
        "  session_id = create_response.session_id\n",
        "  status = \"CONTINUE\"\n",
        "  while status != \"DONE\":\n",
        "      step_response = client_multion.sessions.step(\n",
        "          session_id=session_id,\n",
        "          cmd=multion_prompt,\n",
        "          include_screenshot=True\n",
        "      )\n",
        "\n",
        "      m.add(step_response.message, user_id=\"multion\", metadata={\"category\":\"MultiOn-Message\"})\n",
        "      m.add(step_response.screenshot, user_id=\"multion\", metadata={\"category\":\"MultiOn-Screenshot\"})\n",
        "      print(\"\\n\\n MultiOn Message: \" + step_response.message)\n",
        "      print(\"MultiOn Screenshot: \" + step_response.screenshot)\n",
        "      print(\"MultiOn Status: \" + step_response.status)\n",
        "      status = step_response.status\n",
        "\n",
        "      file_name = \"test{num}.png\"\n",
        "      time.sleep(3)\n",
        "      ss = requests.get(step_response.screenshot)\n",
        "      with open(file_name.format(num=step),'wb') as f:\n",
        "        f.write(ss.content)\n",
        "\n",
        "\n",
        "      if(status == \"NOT_SURE\"):\n",
        "        temp_input = input()\n",
        "        if(messages[-1][\"role\"] == \"user\"):\n",
        "          messages[-1][\"content\"] += temp_input\n",
        "        else:\n",
        "          messages.append({\"role\":\"user\", \"content\": temp_input})\n",
        "\n",
        "        if(len(temp_input) > 0):\n",
        "          multion_prompt = temp_input\n",
        "\n",
        "      else:\n",
        "        response = call_claude(messages, step_response.message, file_name.format(num=step))\n",
        "        m.add(response, user_id = \"claude\", metadata={\"category\":\"Claude-Response\"})\n",
        "        print(\"\\n\\n Claude Response: \" + response)\n",
        "        if(status == \"DONE\" and not (\"STOP_LLM\" in response or \"STOP_HUMAN\" in response)):\n",
        "          status = \"CONTINUE\"\n",
        "        if(\"CONTINUE\" in response):\n",
        "          pass\n",
        "        elif(\"STOP_LLM\" in response):\n",
        "          multion_prompt = generate_COT(messages, first=False)\n",
        "          multion_prompt = multion_prompt + response\n",
        "\n",
        "          if(messages[-1][\"role\"] == \"user\"):\n",
        "            messages[-1][\"content\"] += multion_prompt\n",
        "          else:\n",
        "            messages.append({\"role\":\"user\", \"content\": multion_prompt})\n",
        "        elif(\"STOP_HUMAN\" in response):\n",
        "          temp_input = input()\n",
        "          if(messages[-1][\"role\"] == \"user\"):\n",
        "            messages[-1][\"content\"] += temp_input\n",
        "          else:\n",
        "            messages.append({\"role\":\"user\", \"content\": temp_input})\n",
        "          if(len(temp_input) > 0):\n",
        "            multion_prompt = temp_input\n",
        "\n",
        "          multion_prompt = multion_prompt + response\n",
        "        else:\n",
        "          print(\"3rd LLM says task completed!\")\n",
        "          break\n",
        "      step += 1\n",
        "      if(max_steps and step >= max_steps):\n",
        "        break\n",
        "  return messages, session_id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Tell me the weight of the sony xm4 and find other headphones with a similar weight\"\n",
        "messages, session_id = create_full_loop(user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVivJcvUTSPn",
        "outputId": "fe0c48ee-fedd-4fa3-8bb7-977ca7626d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ðŸ–‡ AgentOps: \u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=b21d8638-f953-43c2-9f8e-98507dbb93dd\u001b[0m\n",
            "INFO:agentops:\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=b21d8638-f953-43c2-9f8e-98507dbb93dd\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROPOSED CHAIN OF THOUGHT:\n",
            "Here is the chain of thought to complete the task:\n",
            "\n",
            "[\n",
            "\"Original-Prompt-From-User\": Find the weight of the Sony XM4 and similar headphones ,\n",
            "\"Step 1: Check Official Website\": Check the official Sony website for the weight of the Sony XM4 headphones ,\n",
            "\"Ask-Question\": \"Can you please confirm if you want to check the weight of the Sony XM4 headphones from the official Sony website or a third-party source?\" ,\n",
            "\"Step 2: Check Official Website\": If the user confirms, check the official Sony website for the weight of the Sony XM4 headphones. If not, proceed to Step 3 ,\n",
            "\"Step 3: Check Third-Party Source\": Check a reputable third-party source such as CNET, Rtings, or Wirecutter for the weight of the Sony XM4 headphones ,\n",
            "\"Step 4: Find Similar Headphones\": Search for other headphones with a similar weight to the Sony XM4. You can use search engines like Google or online marketplaces like Amazon ,\n",
            "\"Ask-Question\": \"What is your preferred price range for the similar headphones?\" ,\n",
            "\"Step 5: Filter Results\": Filter the search results by price range and weight to find headphones with a similar weight to the Sony XM4. You can use filters on online marketplaces or use specific keywords in your search query ,\n",
            "\"Step 6: Compare Results\": Compare the features and specifications of the similar headphones to the Sony XM4 to ensure they meet your requirements. You can use online reviews, product descriptions, and specifications to compare the headphones ,\n",
            "\"Step 7: Provide Results\": Provide the user with the weight of the Sony XM4 headphones and a list of similar headphones with their weights and features.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " MultiOn Message: I am searching for the weight of the Sony XM4 headphones on Google to gather the necessary information.\n",
            "MultiOn Screenshot: https://multion-client-screenshots.s3.us-east-2.amazonaws.com/8978dcc9-e420-4ef7-b34d-264658952e34_1721594283404_screenshot.png\n",
            "MultiOn Status: CONTINUE\n",
            "\n",
            "\n",
            " Claude Response: <<<CONTINUE>>>: <<<N/A>>> (reasoning: The image shows the search results for the weight of the Sony XM4 headphones, which appears to be the requested information. MultiOn seems to be on the right track by performing this search to find the weight details.)\n",
            "\n",
            "\n",
            " MultiOn Message: Memorizing the following information: The weight of the Sony XM4 headphones is 9 ounces.\n",
            "I am going to keep scrolling to find the information I need so I can memorize it.\n",
            "\n",
            "MultiOn Screenshot: https://multion-client-screenshots.s3.us-east-2.amazonaws.com/8978dcc9-e420-4ef7-b34d-264658952e34_1721594300470_screenshot.png\n",
            "MultiOn Status: CONTINUE\n",
            "\n",
            "\n",
            " Claude Response: <<<STOP_HUMAN>>>: <<<The search results clearly show that the weight of the Sony WH-1000XM4 headphones is 2.31 pounds or approximately 10.5 ounces, not 9 ounces as you stated. It seems there may have been a misunderstanding or miscommunication about the actual weight information.>>> (reasoning: The user's stated weight memorized does not match the weight shown in the search results, so clarification from the user is needed to resolve this discrepancy and ensure MultiOn understands the correct weight to memorize.)\n",
            "yes it is 2.31 pounds\n",
            "\n",
            "\n",
            " MultiOn Message: The search results clearly show that the weight of the Sony WH-1000XM4 headphones is 2.31 pounds or approximately 10.5 ounces, not 9 ounces as previously stated. It seems there may have been a misunderstanding or miscommunication about the actual weight information.\n",
            "\n",
            "MultiOn Screenshot: https://multion-client-screenshots.s3.us-east-2.amazonaws.com/8978dcc9-e420-4ef7-b34d-264658952e34_1721594432925_screenshot.png\n",
            "MultiOn Status: DONE\n",
            "\n",
            "\n",
            " Claude Response: <<<CONTINUE>>>: <<<N/A>>> (reasoning: The user has acknowledged and confirmed that the correct weight of the Sony WH-1000XM4 headphones is 2.31 pounds or approximately 10.5 ounces based on the search results shown. MultiOn can now move forward with this accurate weight information memorized.)\n",
            "\n",
            "\n",
            " MultiOn Message: The search results clearly show that the weight of the Sony WH-1000XM4 headphones is 2.31 pounds or approximately 10.5 ounces, not 9 ounces as previously stated. It seems there may have been a misunderstanding or miscommunication about the actual weight information.\n",
            "\n",
            "MultiOn Screenshot: https://multion-client-screenshots.s3.us-east-2.amazonaws.com/8978dcc9-e420-4ef7-b34d-264658952e34_1721594458307_screenshot.png\n",
            "MultiOn Status: DONE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_memories = m.get_all()\n",
        "print(all_memories)"
      ],
      "metadata": {
        "id": "OQApcsrfAeK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QsIksnF0v8QR",
        "outputId": "2aa13374-d48e-490f-fcc0-cb0d7c2fd772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<CONFIRM-VERIFICATION>>>: The LLM has reached a point where eBay is asking for verification to proceed with the purchase. The user needs to complete this verification step on their end. ,\n",
            "<<<ASK-QUESTION>>>: \"Please complete the verification process on eBay and let me know once it's done so I can continue assisting you with the purchase.\" ,\n",
            "<<<WAIT-FOR-USER-RESPONSE>>>: Wait for the user to confirm that they have completed the verification process before proceeding with the next steps. ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms the verification is complete, proceed to add the selected dress to the cart and guide the user through the checkout process. ,\n",
            "<<<REQUEST-CREDENTIALS-IF-NEEDED>>>: If the user has not provided their eBay credentials yet, ask for their username and password to complete the purchase. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay if you intend to make a purchase.\" \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<UNNECESSARY-STEP>>>: The step to wait for user response after asking them to complete the verification process is redundant. The assistant should be able to proceed with the next steps without waiting for confirmation, as the user is already aware of the verification requirement. ,\n",
            "<<<MISORDERED-STEP>>>: The request for credentials should come before the step to proceed to purchase. If the user has not provided their credentials, the assistant cannot proceed with the purchase regardless of whether the verification is complete. ,\n",
            "<<<LACK-OF-CLARITY>>>: The step titled \"CONFIRM-VERIFICATION\" could be clearer. It should specify that the user needs to complete the verification process on eBay before the assistant can continue, rather than just stating that the LLM has reached a point where verification is needed. ,\n",
            "<<<REPETITION-OF-REQUESTS>>>: The assistant should avoid asking for credentials again if they have already been requested earlier in the conversation. Instead, it should check if the credentials are already available before asking again. \n",
            "\n",
            "Overall, the proposed chain of thought could be streamlined for efficiency and clarity.\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<CONFIRM-VERIFICATION>>>: The user needs to complete the verification process on eBay before the assistant can continue with the purchase. This is a necessary step to proceed. ,\n",
            "<<<REQUEST-CREDENTIALS>>>: Before proceeding to purchase, check if the user has provided their eBay credentials. If not, request them to ensure the purchase can be completed. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay if you intend to make a purchase.\" ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user provides their credentials and confirms the verification is complete, proceed to add the selected dress to the cart and guide the user through the checkout process. ,\n",
            "<<<FILTER-RESULTS-IF-NEEDED>>>: If the user has not provided their credentials, remind them that the purchase cannot be completed without them. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you ready to proceed with the purchase now that the verification is complete?\" \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<UNNECESSARY-STEP>>>: The step to confirm verification is redundant since the user has already been informed about the verification process. Instead, focus on the next actionable step, which is obtaining the credentials. ,\n",
            "<<<MISORDERED-LOGIC>>>: The request for credentials should come before confirming the verification process. The assistant should first ensure that the user has provided the necessary credentials before discussing the verification step. ,\n",
            "<<<REPETITIVE-REQUESTS>>>: The proposed chain includes multiple requests for credentials and confirmation of the verification process, which can be streamlined. Instead of asking for credentials again after confirming verification, the assistant should directly proceed to the purchase if the credentials are already provided. ,\n",
            "<<<LACK-OF-CLARITY>>>: The proposed chain does not clarify what the user should do if they have already provided their credentials. It should include a clear path for users who have already completed that step. \n",
            "\n",
            "Overall, the proposed chain of thought could be more concise and logically structured to enhance user experience and efficiency.\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<REQUEST-CREDENTIALS>>>: Check if the user has provided their eBay credentials. If not, request them to ensure the purchase can be completed. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay to proceed with the purchase.\" ,\n",
            "<<<PROCEED-TO-VERIFICATION>>>: Once the user provides their credentials, inform them that they need to complete the verification process on eBay before the assistant can continue with the purchase. ,\n",
            "<<<ASK-QUESTION>>>: \"Please complete the verification process on eBay.\" ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: After the user confirms that they have completed the verification process, proceed to add the selected dress to the cart and guide the user through the checkout process. ,\n",
            "<<<CHECK-CREDENTIALS-STATUS>>>: If the user has already provided their credentials earlier, skip the request and directly inform them about the verification process. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<UNNECESSARY-STEP>>>: The step to check if the user has provided their eBay credentials is redundant. The assistant should always request credentials if the user intends to make a purchase, regardless of previous interactions. This ensures clarity and avoids any assumptions about the user's input. ,\n",
            "<<<MISORDERED-STEP>>>: The step to inform the user about the verification process should come after the user provides their credentials, not as a separate step before confirming the credentials. This can lead to confusion about whether the user needs to provide credentials or if they are already in the process of verification. ,\n",
            "<<<LACK-OF-CLARITY>>>: The proposed chain lacks clarity on what happens if the user does not provide their credentials. It should include a clear instruction on what the assistant will do if the credentials are not provided, such as asking the user to provide them again or explaining the consequences of not providing them. ,\n",
            "<<<REPETITIVE-QUESTION>>>: The question asking the user to complete the verification process is repetitive and could be combined with the previous step about providing credentials. Instead, the assistant could simply state that once the credentials are provided, the user will need to complete the verification process. ,\n",
            "`MORE-LINES-HERE`\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<REQUEST-CREDENTIALS>>>: Request the user's eBay credentials to ensure the purchase can be completed. This is necessary for proceeding with the purchase. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay to proceed with the purchase.\" ,\n",
            "<<<INFORM-VERIFICATION>>>: After the user provides their credentials, inform them that they will need to complete the verification process on eBay before the assistant can continue with the purchase. ,\n",
            "<<<PROCEED-TO-VERIFICATION>>>: \"Once you provide your credentials, please complete the verification process on eBay.\" ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: After the user confirms that they have completed the verification process, proceed to add the selected dress to the cart and guide the user through the checkout process. ,\n",
            "<<<HANDLE-MISSING-CREDENTIALS>>>: If the user does not provide their credentials, explain that the purchase cannot be completed without them and ask them to provide their eBay username and password again. ,\n",
            "<<<ASK-QUESTION>>>: \"Could you please provide your eBay username and password to continue with the purchase?\" \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "status='CONTINUE' message='I am clicking on the \"Add to List\" button to add the selected dress to the cart.\\n' session_id='162c3540-d7c3-452c-8248-d122ac620aa0' url='https://www.amazon.com/ap/signin?openid.return_to=https%3A%2F%2Fwww.amazon.com%2Fgp%2Faw%2Fd%2FB0BQ2DZ8HP&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.assoc_handle=usflex&openid.mode=checkid_setup&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&' screenshot='https://multion-client-screenshots.s3.us-east-2.amazonaws.com/162c3540-d7c3-452c-8248-d122ac620aa0_1721529754068_screenshot.png' metadata=SessionStepSuccessMetadata(temperature=0.2)\n",
            "status='NOT_SURE' message='Please provide your Amazon username and password to proceed with the purchase.\\n' session_id='162c3540-d7c3-452c-8248-d122ac620aa0' url='https://www.amazon.com/ap/signin?openid.return_to=https%3A%2F%2Fwww.amazon.com%2Fgp%2Faw%2Fd%2FB0BQ2DZ8HP&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.assoc_handle=usflex&openid.mode=checkid_setup&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&' screenshot='https://multion-client-screenshots.s3.us-east-2.amazonaws.com/162c3540-d7c3-452c-8248-d122ac620aa0_1721529759019_screenshot.png' metadata=SessionStepSuccessMetadata(temperature=0.2)\n",
            "I don't want to purchase, I just want the link\n",
            "status='DONE' message='Here is the link to the dress you were interested in on Amazon:\\n\\n[Amazon Dress Link](https://www.amazon.com/HELYO-Cocktail-Sleeves-Wedding-Pockets/dp/B0BQ2DZ8HP/ref=sr_1_1?crid=28NQ2CU027AYV&dib=eyJ2IjoiMSJ9.sRYPL9yQpz24JCdF5_uzu22o7rspyV3lBRMk2C8-kuaAHJmYq5nyUWSY9CDzwFpusU1BdaqC55kwvq6sXJVYp8lOj2A4-4zx3yriz4t8P3GGB_CGrzRJSWL9bGEoQrRMpgAD3QzGeYIPN2YSX0BMeFgmkU3zi5uhlAvPBy8s467Us1fJ62WwjHR-KvPT1nFX_NSJI6td_fygz5SOAFsoa273auucJED-C0l-QRZ1QhT7gnY6-aTgmt4InjNYOEkHzxfJdAGxoG4leSuq4Qr3HEUCwlgMF1DOkzZOD48O-jc.Q02poNzpDWyAa03L77IyGCg3t92vsjoCOu0yiKnlJvY&dib_tag=se&keywords=semi%2Bformal%2Bdress%2Bred%2Bor%2Bblue%2Bfloral%2Bpattern%2Bsmall%2Bsize&qid=1721529638&sprefix=%2Caps%2C166&sr=8-1&th=1&psc=1)\\n' session_id='162c3540-d7c3-452c-8248-d122ac620aa0' url='https://www.amazon.com/ap/signin?openid.return_to=https%3A%2F%2Fwww.amazon.com%2Fgp%2Faw%2Fd%2FB0BQ2DZ8HP&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.assoc_handle=usflex&openid.mode=checkid_setup&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&' screenshot='https://multion-client-screenshots.s3.us-east-2.amazonaws.com/162c3540-d7c3-452c-8248-d122ac620aa0_1721529848646_screenshot.png' metadata=SessionStepSuccessMetadata(temperature=0.2)\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<REQUEST-CREDENTIALS>>>: Request the user's eBay credentials to ensure the purchase can be completed. This is necessary for proceeding with the purchase. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay to proceed with the purchase.\" ,\n",
            "<<<INFORM-VERIFICATION>>>: After the user provides their credentials, inform them that they will need to complete the verification process on eBay before the assistant can continue with the purchase. ,\n",
            "<<<PROCEED-TO-VERIFICATION>>>: \"Once you provide your credentials, please complete the verification process on eBay.\" ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: After the user confirms that they have completed the verification process, proceed to add the selected dress to the cart and guide the user through the checkout process. ,\n",
            "<<<HANDLE-MISSING-CREDENTIALS>>>: If the user does not provide their credentials, explain that the purchase cannot be completed without them and ask them to provide their eBay username and password again. ,\n",
            "<<<ASK-QUESTION>>>: \"If you haven't provided your eBay credentials yet, could you please do so to continue with the purchase?\" \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<UNNECESSARY-REPEATED-REQUESTS>>>: The proposed chain of thought redundantly requests the user's eBay credentials multiple times. It should only ask for credentials once and then proceed to the next steps without reiterating the request. ,\n",
            "<<<LACK-OF-CLARITY-ON-VERIFICATION>>>: The step regarding informing the user about the verification process is vague. It should specify what the verification process entails and why it is necessary, rather than just stating that they need to complete it. ,\n",
            "<<<MISORDERED-LOGIC>>>: The step to inform the user about the verification process should come after the user provides their credentials, not before. This would create a more logical flow in the conversation. ,\n",
            "<<<EXCESSIVE-DETAILS-ON-VERIFICATION>>>: The proposed chain includes a step that states the user should complete the verification process after providing credentials. This could be simplified to just informing the user that they may need to verify their identity after logging in, without needing a separate step for it. ,\n",
            "<<<LACK-OF-USER-ENGAGEMENT>>>: The chain does not include any engagement with the user after the initial request for credentials. It should include a follow-up question or prompt to keep the user involved in the process, such as asking if they have any questions about the purchase or the dress options.\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<REQUEST-CREDENTIALS>>>: Request the user's eBay credentials to ensure the purchase can be completed. This is necessary for proceeding with the purchase. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay to proceed with the purchase.\" ,\n",
            "<<<INFORM-VERIFICATION>>>: After the user provides their credentials, inform them that they may need to verify their identity on eBay after logging in, which is a standard security measure. ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. ,\n",
            "<<<HANDLE-MISSING-CREDENTIALS>>>: If the user does not provide their credentials, explain that the purchase cannot be completed without them and ask them to provide their eBay username and password. ,\n",
            "<<<ENGAGE-USER>>>: After requesting credentials, ask the user if they have any questions about the dress options or the purchasing process to keep them engaged. ,\n",
            "<<<ASK-QUESTION>>>: \"Do you have any questions about the dresses or the purchasing process before we continue?\" \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<UNNECESSARY-REPEATED-REQUESTS>>>: The proposed chain of thought redundantly requests the user's eBay credentials without first confirming if they are ready to proceed with the purchase. It would be more efficient to first confirm the user's intent to buy before asking for sensitive information. ,\n",
            "<<<LACK-OF-USER-ENGAGEMENT>>>: The step to engage the user after requesting credentials is good, but it should be placed before asking for credentials. This way, the user feels more involved in the process and may be more willing to provide their information. ,\n",
            "<<<MISORDERED-LOGIC>>>: The step to inform the user about potential verification after logging in should come after the user has provided their credentials, not before. This creates a more logical flow and avoids overwhelming the user with information before they have taken action. ,\n",
            "<<<REINFORCE-SECURITY-IMPORTANCE>>>: While it is good to inform the user about verification, it would be beneficial to emphasize the importance of keeping their credentials secure and not sharing them in public forums or with untrusted sources. This could be a separate step to reinforce security awareness. ,\n",
            "`MORE-LINES-HERE`\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<CONFIRM-PURCHASE-INTENT>>>: Ask the user if they are ready to proceed with the purchase of the dress. This will help gauge their intent before requesting sensitive information. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you ready to proceed with the purchase of the dress?\" ,\n",
            "<<<REQUEST-CREDENTIALS>>>: If the user confirms they are ready to purchase, request their eBay credentials to ensure the purchase can be completed. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay to proceed with the purchase.\" ,\n",
            "<<<INFORM-VERIFICATION>>>: After the user provides their credentials, inform them that they may need to verify their identity on eBay after logging in, which is a standard security measure. ,\n",
            "<<<REINFORCE-SECURITY-IMPORTANCE>>>: Emphasize the importance of keeping their credentials secure and not sharing them in public forums or with untrusted sources. ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. ,\n",
            "<<<HANDLE-MISSING-CREDENTIALS>>>: If the user does not provide their credentials, explain that the purchase cannot be completed without them and ask them to provide their eBay username and password. ,\n",
            "<<<ENGAGE-USER>>>: After confirming their intent to purchase, ask the user if they have any questions about the dress options or the purchasing process to keep them engaged. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<LOGICAL-FLOW-ISSUE>>>: The proposed chain of thought jumps directly to confirming purchase intent without first ensuring that the user has selected a dress from the options presented. It would be more logical to first present the dress options and then ask if they are ready to proceed with a purchase. \n",
            "<<<REPETITIVE-REQUESTS>>>: The step to request credentials is repeated in both the \"REQUEST-CREDENTIALS\" and \"HANDLE-MISSING-CREDENTIALS\" sections. Instead, you could streamline this by combining these steps into one that handles both scenarios more efficiently.\n",
            "<<<LACK-OF-USER-ENGAGEMENT>>>: The proposed chain lacks a step to engage the user after presenting the dress options. Asking for their feedback on the options or if they would like to see more choices would enhance user interaction and satisfaction.\n",
            "<<<SECURITY-EMPHASIS-PLACEMENT>>>: While it is important to emphasize security, the placement of the \"REINFORCE-SECURITY-IMPORTANCE\" step may be better suited after the user has provided their credentials, rather than before. This way, it can serve as a reminder just before they proceed with sensitive actions. \n",
            "<<<UNNECESSARY-STEP>>>: The \"INFORM-VERIFICATION\" step may be unnecessary if the user is already aware of eBay's verification process. Instead, you could simply mention it briefly after they log in, if it becomes relevant. \n",
            "\n",
            "Overall, the proposed chain could benefit from a more logical flow, reduced redundancy, and enhanced user engagement.\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<PRESENT-DRESS-OPTIONS>>>: After filtering the search results, present the user with a curated list of suitable dresses based on their criteria. This is the next logical step after finding options. ,\n",
            "<<<ASK-FOR-FEEDBACK>>>: Engage the user by asking for their feedback on the presented dress options. This will help gauge their interest and preferences. ,\n",
            "<<<ASK-QUESTION>>>: \"Here are some dress options that match your criteria. Which one do you like, or would you like to see more options?\" ,\n",
            "<<<CONFIRM-PURCHASE-INTENT>>>: Once the user selects a dress they are interested in, ask if they are ready to proceed with the purchase. This ensures they are committed to buying before requesting sensitive information. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you ready to proceed with the purchase of the selected dress?\" ,\n",
            "<<<REQUEST-CREDENTIALS>>>: If the user confirms they are ready to purchase, request their eBay credentials to ensure the purchase can be completed. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay to proceed with the purchase.\" ,\n",
            "<<<HANDLE-MISSING-CREDENTIALS>>>: If the user does not provide their credentials, explain that the purchase cannot be completed without them and ask them to provide their eBay username and password. ,\n",
            "<<<REINFORCE-SECURITY-IMPORTANCE>>>: After the user provides their credentials, remind them to keep their credentials secure and not share them in public forums or with untrusted sources. ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "status='DONE' message='Here are some dress options that match your criteria. Which one do you like, or would you like to see more options?\\n\\n1. [Amazon Dress Link](https://www.amazon.com/HELYO-Cocktail-Sleeves-Wedding-Pockets/dp/B0BQ2DZ8HP/ref=sr_1_1?crid=28NQ2CU027AYV&dib=eyJ2IjoiMSJ9.sRYPL9yQpz24JCdF5_uzu22o7rspyV3lBRMk2C8-kuaAHJmYq5nyUWSY9CDzwFpusU1BdaqC55kwvq6sXJVYp8lOj2A4-4zx3yriz4t8P3GGB_CGrzRJSWL9bGEoQrRMpgAD3QzGeYIPN2YSX0BMeFgmkU3zi5uhlAvPBy8s467Us1fJ62WwjHR-KvPT1nFX_NSJI6td_fygz5SOAFsoa273auucJED-C0l-QRZ1QhT7gnY6-aTgmt4InjNYOEkHzxfJdAGxoG4leSuq4Qr3HEUCwlgMF1DOkzZOD48O-jc.Q02poNzpDWyAa03L77IyGCg3t92vsjoCOu0yiKnlJvY&dib_tag=se&keywords=semi%2Bformal%2Bdress%2Bred%2Bor%2Bblue%2Bfloral%2Bpattern%2Bsmall%2Bsize&qid=1721529638&sprefix=%2Caps%2C166&sr=8-1&th=1&psc=1)\\n\\nPlease let me know if you like this option or if you would like to see more options.\\n' session_id='162c3540-d7c3-452c-8248-d122ac620aa0' url='https://www.amazon.com/ap/signin?openid.return_to=https%3A%2F%2Fwww.amazon.com%2Fgp%2Faw%2Fd%2FB0BQ2DZ8HP&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.assoc_handle=usflex&openid.mode=checkid_setup&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&' screenshot='https://multion-client-screenshots.s3.us-east-2.amazonaws.com/162c3540-d7c3-452c-8248-d122ac620aa0_1721529898878_screenshot.png' metadata=SessionStepSuccessMetadata(temperature=0.2)\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<PRESENT-DRESS-OPTIONS>>>: After filtering the search results, present the user with a curated list of suitable dresses based on their criteria. This is the next logical step after finding options. ,\n",
            "<<<ASK-FOR-FEEDBACK>>>: Engage the user by asking for their feedback on the presented dress options. This will help gauge their interest and preferences. ,\n",
            "<<<ASK-QUESTION>>>: \"Here are some dress options that match your criteria. Which one do you like, or would you like to see more options?\" ,\n",
            "<<<CONFIRM-PURCHASE-INTENT>>>: Once the user selects a dress they are interested in, ask if they are ready to proceed with the purchase. This ensures they are committed to buying before requesting sensitive information. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you ready to proceed with the purchase of the selected dress?\" ,\n",
            "<<<REQUEST-CREDENTIALS>>>: If the user confirms they are ready to purchase, request their eBay credentials to ensure the purchase can be completed. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay to proceed with the purchase.\" ,\n",
            "<<<HANDLE-MISSING-CREDENTIALS>>>: If the user does not provide their credentials, explain that the purchase cannot be completed without them and ask them to provide their eBay username and password. ,\n",
            "<<<REINFORCE-SECURITY-IMPORTANCE>>>: After the user provides their credentials, remind them to keep their credentials secure and not share them in public forums or with untrusted sources. ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<LOGICAL-ORDERING-ISSUE>>>: The proposed chain of thought jumps directly to presenting dress options without confirming the user's preferences or ensuring they are ready to purchase. It would be more logical to first confirm the user's interest in the options found before presenting them. \n",
            "<<<REDUNDANT-STEP>>>: The step to handle missing credentials is somewhat redundant. Instead of having a separate step for this, it could be integrated into the request for credentials, making the process smoother and more efficient.\n",
            "<<<LACK-OF-CLARITY-ON-SECURITY>>>: While reinforcing the importance of security is good, it should be more specific about how to keep credentials secure rather than just stating that they should not be shared. This could help the user understand the importance of security better.\n",
            "<<<NEED-FOR-USER-ENGAGEMENT>>>: The proposed chain lacks a step to engage the user in a conversation about their preferences after presenting the options. Asking for feedback on the options could help refine the search further and ensure the user is satisfied with the choices presented. \n",
            "<<<MISSING-ALTERNATIVE-OPTIONS>>>: The chain does not include a step to ask if the user is open to exploring different styles or options outside their initial preferences, which could broaden their choices and enhance their shopping experience.\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<CONFIRM-INTEREST>>>: Before presenting dress options, confirm the user's interest in shopping for a dress and clarify their preferences. This ensures that the assistant is aligned with the user's needs. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you still interested in shopping for a dress? If so, do you have any specific styles or colors in mind?\" ,\n",
            "<<<PRESENT-DRESS-OPTIONS>>>: After confirming the user's interest and preferences, present a curated list of suitable dresses based on their criteria. This is the next logical step after understanding their needs. ,\n",
            "<<<ASK-FOR-FEEDBACK>>>: Engage the user by asking for their feedback on the presented dress options. This will help gauge their interest and preferences. ,\n",
            "<<<ASK-QUESTION>>>: \"Here are some dress options that match your criteria. Which one do you like, or would you like to see more options?\" ,\n",
            "<<<EXPLORE-ALTERNATIVE-OPTIONS>>>: Ask the user if they are open to exploring different styles or options outside their initial preferences to enhance their shopping experience. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you open to exploring different styles or options outside your initial preferences?\" ,\n",
            "<<<CONFIRM-PURCHASE-INTENT>>>: Once the user selects a dress they are interested in, ask if they are ready to proceed with the purchase. This ensures they are committed to buying before requesting sensitive information. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you ready to proceed with the purchase of the selected dress?\" ,\n",
            "<<<REQUEST-CREDENTIALS>>>: If the user confirms they are ready to purchase, request their eBay credentials to ensure the purchase can be completed. Integrate the handling of missing credentials into this step for efficiency. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay to proceed with the purchase. If you haven't provided them yet, please do so.\" ,\n",
            "<<<REINFORCE-SECURITY-IMPORTANCE>>>: After the user provides their credentials, remind them to keep their credentials secure by using strong passwords and not sharing them in public forums or with untrusted sources. ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: THE INITIAL CONFIRMATION STEP IS REDUNDANT ,\n",
            "The proposed chain begins with confirming the user's interest in shopping for a dress, which may be unnecessary since the user has already expressed their intent to shop. Instead, it would be more efficient to directly present the dress options based on the previously gathered criteria.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: LACK OF SPECIFICITY IN PREFERENCES ,\n",
            "While the proposed chain includes a step to clarify the user's preferences, it does not specify that the assistant should gather detailed information about occasion, budget, style, and size again. This could lead to confusion or misalignment with the user's original criteria.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: MISORDERED STEPS IN THE PROCESS ,\n",
            "The step to present dress options should logically follow the confirmation of the user's preferences, but it is placed before confirming the user's purchase intent. This could lead to presenting options without ensuring the user is still interested in making a purchase.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: INTEGRATION OF CREDENTIALS REQUEST IS INEFFICIENT ,\n",
            "The request for credentials is separated from the confirmation of purchase intent. It would be more efficient to combine these steps, asking for credentials only after confirming the user's readiness to purchase, rather than introducing it as a separate step.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: SECURITY REMINDER IS UNNECESSARY AT THIS STAGE ,\n",
            "While reinforcing the importance of security is generally a good practice, including it immediately after requesting credentials may not be necessary. It could be perceived as patronizing or redundant, especially if the user is already aware of security practices. \n",
            "\n",
            "Overall, the proposed chain of thought could benefit from a more streamlined approach that avoids redundancy and maintains a logical flow in the conversation.\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<GATHER-USER-PREFERENCES>>>: Reiterate the user's preferences for the dress, including occasion, budget, style, and size, to ensure alignment with their original criteria. This step is crucial for presenting relevant options. ,\n",
            "<<<ASK-QUESTION>>>: \"Can you please confirm your preferences for the dress, including the occasion, budget, style, and size?\" ,\n",
            "<<<PRESENT-DRESS-OPTIONS>>>: After gathering the user's preferences, present a curated list of suitable dresses based on their criteria. This is the next logical step after confirming their needs. ,\n",
            "<<<ASK-FOR-FEEDBACK>>>: Engage the user by asking for their feedback on the presented dress options. This will help gauge their interest and preferences. ,\n",
            "<<<ASK-QUESTION>>>: \"Here are some dress options that match your criteria. Which one do you like, or would you like to see more options?\" ,\n",
            "<<<EXPLORE-ALTERNATIVE-OPTIONS>>>: Ask the user if they are open to exploring different styles or options outside their initial preferences to enhance their shopping experience. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you open to exploring different styles or options outside your initial preferences?\" ,\n",
            "<<<CONFIRM-PURCHASE-INTENT>>>: Once the user selects a dress they are interested in, ask if they are ready to proceed with the purchase. This ensures they are committed to buying before requesting sensitive information. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you ready to proceed with the purchase of the selected dress?\" ,\n",
            "<<<REQUEST-CREDENTIALS>>>: If the user confirms they are ready to purchase, request their eBay credentials to ensure the purchase can be completed. Combine this with the confirmation of intent for efficiency. ,\n",
            "<<<ASK-QUESTION>>>: \"Please provide your username and password for eBay to proceed with the purchase.\" ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<UNNECESSARY-REITERATION>>>: The step to reiterate the user's preferences is redundant since the assistant has already memorized the user's criteria. Instead, the assistant should directly present the dress options based on the previously gathered information. ,\n",
            "<<<MISORDERED-LOGIC>>>: The step to present dress options should come before asking for feedback. The user needs to see the options first to provide informed feedback. ,\n",
            "<<<LACK-OF-CLARITY-ON-CREDENTIALS>>>: The request for eBay credentials should specify that the user needs to log in to their account on eBay, not just provide credentials. This ensures clarity on the action required from the user. ,\n",
            "<<<REPEATED-EXPLORATION>>>: Asking if the user is open to exploring different styles after presenting options may be unnecessary. This question could be integrated earlier in the process, perhaps right after confirming their preferences, to streamline the conversation. ,\n",
            "<<<SENSITIVE-INFO-REQUEST-ORDER>>>: The request for credentials should come after confirming the user's intent to purchase, but it should also ensure that the user is aware of the need to log in to complete the purchase, rather than just asking for credentials without context.\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<PRESENT-DRESS-OPTIONS>>>: Directly present a curated list of suitable dresses based on the previously gathered criteria. This is the next logical step after confirming the user's interest in shopping. ,\n",
            "<<<ASK-FOR-FEEDBACK>>>: After presenting the dress options, engage the user by asking for their feedback on the options. This will help gauge their interest and preferences. ,\n",
            "<<<ASK-QUESTION>>>: \"Here are some dress options that match your criteria. Which one do you like, or would you like to see more options?\" ,\n",
            "<<<CONFIRM-PURCHASE-INTENT>>>: Once the user selects a dress they are interested in, ask if they are ready to proceed with the purchase. This ensures they are committed to buying before requesting sensitive information. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you ready to proceed with the purchase of the selected dress?\" ,\n",
            "<<<REQUEST-CREDENTIALS>>>: If the user confirms they are ready to purchase, request their eBay credentials and clarify that they need to log in to their account to complete the purchase. ,\n",
            "<<<ASK-QUESTION>>>: \"Please log in to your eBay account and provide your username and password to proceed with the purchase.\" ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "status='DONE' message='Here are some dress options that match your criteria. Which one do you like, or would you like to see more options?\\n\\n1. [Amazon Dress Link](https://www.amazon.com/HELYO-Cocktail-Sleeves-Wedding-Pockets/dp/B0BQ2DZ8HP/ref=sr_1_1?crid=28NQ2CU027AYV&dib=eyJ2IjoiMSJ9.sRYPL9yQpz24JCdF5_uzu22o7rspyV3lBRMk2C8-kuaAHJmYq5nyUWSY9CDzwFpusU1BdaqC55kwvq6sXJVYp8lOj2A4-4zx3yriz4t8P3GGB_CGrzRJSWL9bGEoQrRMpgAD3QzGeYIPN2YSX0BMeFgmkU3zi5uhlAvPBy8s467Us1fJ62WwjHR-KvPT1nFX_NSJI6td_fygz5SOAFsoa273auucJED-C0l-QRZ1QhT7gnY6-aTgmt4InjNYOEkHzxfJdAGxoG4leSuq4Qr3HEUCwlgMF1DOkzZOD48O-jc.Q02poNzpDWyAa03L77IyGCg3t92vsjoCOu0yiKnlJvY&dib_tag=se&keywords=semi%2Bformal%2Bdress%2Bred%2Bor%2Bblue%2Bfloral%2Bpattern%2Bsmall%2Bsize&qid=1721529638&sprefix=%2Caps%2C166&sr=8-1&th=1&psc=1)\\n\\nPlease let me know if you like this option or if you would like to see more options.\\n' session_id='162c3540-d7c3-452c-8248-d122ac620aa0' url='https://www.amazon.com/ap/signin?openid.return_to=https%3A%2F%2Fwww.amazon.com%2Fgp%2Faw%2Fd%2FB0BQ2DZ8HP&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.assoc_handle=usflex&openid.mode=checkid_setup&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&' screenshot='https://multion-client-screenshots.s3.us-east-2.amazonaws.com/162c3540-d7c3-452c-8248-d122ac620aa0_1721529969125_screenshot.png' metadata=SessionStepSuccessMetadata(temperature=0.2)\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<PRESENT-DRESS-OPTIONS>>>: Directly present a curated list of suitable dresses based on the previously gathered criteria. This is the next logical step after confirming the user's interest in shopping. ,\n",
            "<<<ASK-FOR-FEEDBACK>>>: After presenting the dress options, engage the user by asking for their feedback on the options. This will help gauge their interest and preferences. ,\n",
            "<<<ASK-QUESTION>>>: \"Here are some dress options that match your criteria. Which one do you like, or would you like to see more options?\" ,\n",
            "<<<CONFIRM-PURCHASE-INTENT>>>: Once the user selects a dress they are interested in, ask if they are ready to proceed with the purchase. This ensures they are committed to buying before requesting sensitive information. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you ready to proceed with the purchase of the selected dress?\" ,\n",
            "<<<REQUEST-CREDENTIALS>>>: If the user confirms they are ready to purchase, request their eBay credentials and clarify that they need to log in to their account to complete the purchase. ,\n",
            "<<<ASK-QUESTION>>>: \"Please log in to your eBay account and provide your username and password to proceed with the purchase.\" ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<LOGICAL-ORDER-ISSUE>>>: The proposed chain of thought jumps directly to presenting dress options without confirming the user's intent to purchase first. It would be more logical to first confirm the user's interest in purchasing before presenting options, as this ensures that the user is ready to engage in the buying process. \n",
            "<<<REDUNDANT-STEP>>>: The step to ask for feedback after presenting dress options may be unnecessary if the user has already expressed a desire to purchase. Instead, it would be more efficient to directly ask if they want to proceed with a purchase after presenting the options.\n",
            "<<<CREDENTIALS-REQUEST-CLARITY>>>: The request for credentials should specify that the user needs to log in to their eBay account, but it should also clarify that they should not share their credentials with anyone else. This is important for user security and trust.\n",
            "<<<SEQUENCE-IMPROVEMENT>>>: The sequence of steps could be improved by first confirming the user's intent to purchase, then presenting the options, and finally asking for credentials. This would create a more streamlined and logical flow for the user. \n",
            "\n",
            "Overall, the proposed chain of thought needs to ensure that it follows a logical order and avoids unnecessary steps to enhance user experience.\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<CONFIRM-PURCHASE-INTENT>>>: Start by confirming the user's intent to purchase a dress. This ensures they are ready to engage in the buying process. ,\n",
            "<<<ASK-QUESTION>>>: \"Are you ready to proceed with purchasing a dress?\" ,\n",
            "<<<PRESENT-DRESS-OPTIONS>>>: If the user confirms they are ready to purchase, present a curated list of suitable dresses based on the previously gathered criteria. This is the next logical step after confirming their intent. ,\n",
            "<<<ASK-QUESTION>>>: \"Here are some dress options that match your criteria. Which one would you like to purchase?\" ,\n",
            "<<<REQUEST-CREDENTIALS>>>: Once the user selects a dress they are interested in, request their eBay credentials and clarify that they need to log in to their account to complete the purchase. Also, remind them to keep their credentials secure and not share them with anyone. ,\n",
            "<<<ASK-QUESTION>>>: \"Please log in to your eBay account and provide your username and password to proceed with the purchase. Remember to keep your credentials secure.\" ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: After the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: THE INITIAL CONFIRMATION STEP IS REDUNDANT ,\n",
            "The proposed chain starts with confirming the user's intent to purchase a dress, which has already been established in the previous steps. Since the user has already indicated their criteria and the assistant has found options, this step can be skipped to streamline the process.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: PRESENTING DRESS OPTIONS SHOULD BE MORE DETAILED ,\n",
            "While the proposed chain suggests presenting dress options, it lacks specificity about how these options will be curated. It would be beneficial to mention that the options will be based on the previously gathered criteria, ensuring the user understands the relevance of the options being presented.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: REQUESTING CREDENTIALS SHOULD BE MORE SEAMLESS ,\n",
            "The request for eBay credentials should be framed in a way that emphasizes the need for security and privacy. Instead of just asking for credentials, it could be beneficial to remind the user of the importance of keeping their information secure without making it sound overly formal or alarming.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: LOGICAL FLOW COULD BE IMPROVED ,\n",
            "The flow from presenting dress options to requesting credentials could be more logically connected. It would be better to first present the options, allow the user to select one, and then request credentials in a single step rather than separating them into two distinct actions. This would create a smoother transition in the conversation.\n",
            "\n",
            "Overall, the proposed chain of thought could benefit from a more streamlined approach that avoids redundancy and enhances clarity in the user experience.\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED CHAIN OF THOUGHT:\n",
            "[\n",
            "<<<ORIGINAL-PROMPT-FROM-USER>>>: Shopping for a dress ,\n",
            "<<<PRESENT-DRESS-OPTIONS>>>: Present a curated list of suitable dresses based on the previously gathered criteria, ensuring the user understands that these options are tailored to their preferences. ,\n",
            "<<<ASK-QUESTION>>>: \"Here are some dress options that match your criteria. Which one would you like to purchase?\" ,\n",
            "<<<REQUEST-CREDENTIALS>>>: After the user selects a dress they are interested in, seamlessly request their eBay credentials. Emphasize the importance of security and privacy when sharing their information. ,\n",
            "<<<ASK-QUESTION>>>: \"Please log in to your eBay account and provide your username and password to proceed with the purchase. Remember to keep your credentials secure and private.\" ,\n",
            "<<<PROCEED-TO-PURCHASE>>>: Once the user confirms they have logged in and completed any necessary verification, proceed to add the selected dress to the cart and guide the user through the checkout process. \n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "FEEDBACK\n",
            "Here is some feedback for the chain of thought so far:\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: LOGICAL SEQUENCE ISSUES ,\n",
            "The proposed chain of thought jumps directly to presenting dress options without confirming the user's selection first. It should first ask the user if they would like to view more details about the dresses or proceed to purchase before presenting the options. This ensures that the user is engaged in the decision-making process.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: CREDENTIALS REQUEST TIMING ,\n",
            "Requesting credentials immediately after presenting options may be premature. The assistant should first confirm the user's intent to purchase a specific dress before asking for sensitive information like login credentials. This step should come after the user expresses interest in a particular dress.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: SECURITY EMPHASIS ,\n",
            "While it is good to emphasize security and privacy when asking for credentials, the phrasing could be improved. Instead of saying \"Please log in to your eBay account and provide your username and password,\" it would be better to say, \"Please provide your eBay username and password to proceed with the purchase.\" This keeps the focus on the action needed without implying that the assistant is asking the user to log in themselves.\n",
            "\n",
            "<<<TITLE-OF-FEEDBACK-SEPARATED-BY-HYPHEN-ALL-CAPS>>>: MISSING USER ENGAGEMENT ,\n",
            "The proposed chain lacks a step to engage the user after presenting the dress options. It should include a question that invites the user to express their preferences or ask for more details about the dresses before proceeding to the purchase stage. This would enhance user interaction and satisfaction.\n",
            "\n",
            "Overall, the proposed chain of thought needs to ensure a logical flow that prioritizes user engagement and confirms intent before moving to sensitive actions like credential requests.\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a2b429632dc4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;31m# LLM 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msystem_prompt_llm1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 643\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    644\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         )\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 942\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1032\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;31m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0;31m# different thread if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         return self._request(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "while messages[-1][\"role\"] != \"assistant\" or \"DONE-WITH-TASK\" not in messages[-1][\"content\"]:\n",
        "    # LLM 1\n",
        "    completion = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[{\"role\": \"system\", \"content\": system_prompt_llm1}] + messages,\n",
        "      temperature=temperature,\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content\n",
        "    messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "    print(\"PROPOSED CHAIN OF THOUGHT:\")\n",
        "    print(response)\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    for i in range(3):\n",
        "      # LLM 2\n",
        "      completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"system\", \"content\": system_prompt_llm2}, {\"role\": \"user\", \"content\": \"\\n\".join(list(map(str, [messages[0], \"Proposed chain of thought to solve task from current state:\", messages[-1]])))}],\n",
        "        temperature=temperature,\n",
        "      )\n",
        "\n",
        "      response = completion.choices[0].message.content\n",
        "      messages.append({\"role\": \"user\", \"content\": response})\n",
        "      print(\"FEEDBACK\")\n",
        "      print(response)\n",
        "      print(\"\\n\\n\")\n",
        "\n",
        "      # LLM 1\n",
        "      completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"system\", \"content\": system_prompt_llm1}] + messages,\n",
        "        temperature=temperature,\n",
        "      )\n",
        "\n",
        "      response = completion.choices[0].message.content\n",
        "      messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "      print(\"PROPOSED CHAIN OF THOUGHT:\")\n",
        "      print(response)\n",
        "      print(\"\\n\\n\")\n",
        "\n",
        "    final_prompt = messages[-1][\"content\"]\n",
        "\n",
        "    current_prompt = final_prompt\n",
        "    step_response = client_multion.sessions.step(\n",
        "        session_id=create_response.session_id,\n",
        "        cmd=current_prompt,\n",
        "        include_screenshot=True\n",
        "    )\n",
        "    step_responses.append(step_response)\n",
        "    status = step_response.status\n",
        "    print(step_response)\n",
        "\n",
        "    for i in range(max_iters-1):\n",
        "        if status not in [\"CONTINUE\", \"DONE\"]:\n",
        "            temp_input = input()\n",
        "            current_prompt = current_prompt if len(temp_input) == 0 else temp_input\n",
        "            step_response = client_multion.sessions.step(\n",
        "                session_id=create_response.session_id,\n",
        "                cmd=current_prompt,\n",
        "                include_screenshot=True\n",
        "            )\n",
        "        elif status == \"DONE\":\n",
        "            break\n",
        "        elif status == \"CONTINUE\":\n",
        "            step_response = client_multion.sessions.step(\n",
        "                session_id=create_response.session_id,\n",
        "                cmd=current_prompt,\n",
        "                include_screenshot=True\n",
        "            )\n",
        "        step_responses.append(step_response)\n",
        "        status = step_response.status\n",
        "        print(step_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O864m6eDDdT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}